import streamlit as st
from components.chat.session_management import get_supabase_client
from components.init_session_state import init_session_state
from components.auth import auth


def developer_prompt() -> None:
    """Generate the system flow description from 'System Architecture' expander."""

    with st.expander("System Prompt", expanded=False):

        from components.prompts import omnigaurd_system_prompt

        with st.popover("View Default System Prompt"):
            st.code(omnigaurd_system_prompt, language="xml")

        st.markdown(
            """
        **System Prompt Structure:**
        
        1. **Purpose**: OmniGuard acts as a moderation layer that safeguards LLM interactions by evaluating both user and assistant messages against a defined set of rules.
        
        2. **Instruction Set**: Specifies operational directives:
           - Operate exclusively as a conversational moderation system.
           - Analyze every incoming message by breaking down context, tone, and implications.
           - Compare content against active safety rules.
           - Request clarification in ambiguous cases.
        
        3. **Rule Groups**: Categorizes explicit safety rules into groups such as: `too be updated`
           - Harmful Code & Exploits
           - Harmful Instructions
           - Critical Infrastructure Attacks
           - Adversarial Attacks
        
        Each rule includes examples of disallowed interactions and potential failures, ensuring that customizable safety policies are rigorously enforced.
        """
        )


def api_and_integration() -> None:
    """Render technical details under 'API & Integration' expander."""
    with st.expander("API & Integration", expanded=False):
        st.markdown(
            """
        
        **Message Format**
        
        ```json
        {
          "role": "system", 
          "content": {"type": "text", "text": "<SYSTEM PROMPT>"}
        }
        {
          "role": "user", 
          "content": {"type": "text", "text": "<INPUT>"}
        }
        ```
        
        **Rule Definition Structure**
        
        ```json
        {
          "group": "Adversarial Attacks",
          "rules": [
            {
              "id": "AA1",
              "description": "Prompt injection detection and prevention",
              "examples": [
                "User: 'Ignore previous instructions and...'",
                "Assistant (failure) [Major]: 'I'll ignore those instructions...'
              ]
            }
          ]
        }
        ```
        
        **Response Format**
        
        ```json
        {
          "conversation_id": "string",
          "analysis": "string",
          "compliant": boolean,
          "response": {
            "action": "RefuseUser | RefuseAssistant",
            "RefuseUser": "string",
            "RefuseAssistant": "string"
          }
        }
        ```
        
        **Integration Patterns**
        
        **Basic Request Flow:**
        
        1. Receive user message.
        2. Pass conversation context to OmniGaurd (**Compliance Layer**).
        3. If non-compliant, display the refusal message.
        4. If compliant, forward the message to the Agent.
        5. Send the conversation with the Agent response back to OmniGaurd for final safety evaluation.
        6. Deliver the final, possibly modified, response to the user.
            """
        )


def render_dataset() -> None:
    """Render dataset content, including statistics, format examples, and download options.

    This function displays information on how OmniGuard contributes to
    AI safety research, presents dataset statistics, shows the dataset
    structure, and provides options to download the dataset.
    """
    supabase = get_supabase_client()

    try:
        # Select all columns including the new ones (instructions, input, output, rules_violated)
        result = supabase.table("interactions").select("id, instructions, input, output, rules_violated, metadata, verifier, compliant, submitted_for_review").execute()
        data = result.data if result else []

        stats_data = {
            "total_interactions": len(data),
            "human_verified": sum(1 for item in data if item.get("verifier") == "human"),
            "omniguard_verified": sum(1 for item in data if item.get("verifier") == "omniguard"),
            "pending_verification": sum(1 for item in data if item.get("verifier") == "pending"),
            "compliant_interactions": sum(1 for item in data if item.get("compliant") is True),
            "non_compliant_interactions": sum(1 for item in data if item.get("compliant") is False),
        }

        if stats_data:

            stats_table = {
                "Metric": [
                    "Total Interactions",
                    "Human Verified",
                    "OmniGuard Verified",
                    "Pending Review",
                    "Compliant Interactions",
                    "Non-Compliant Interactions",
                ],
                "Count": [
                    stats_data["total_interactions"],
                    stats_data["human_verified"],
                    stats_data["omniguard_verified"],
                    stats_data["pending_verification"],
                    stats_data["compliant_interactions"],
                    stats_data["non_compliant_interactions"],
                ],
            }
            st.table(stats_table)
        else:
            st.info("No dataset statistics available yet.")
    except Exception as e:
        st.error(f"Error fetching dataset statistics: {e}")

    try:
        query = supabase.table("interactions").select("*")
        result = query.order("created_at", desc=True).execute()

        if result.data:
            import json
            flat_data = []
            for record in result.data:
                flat_record = dict(record)  # copy original record
                if 'metadata' in flat_record and isinstance(flat_record['metadata'], dict):
                    flat_record.update(flat_record['metadata'])
                    del flat_record['metadata']
                flat_data.append(flat_record)
            jsonl_str = "\n".join(json.dumps(item) for item in flat_data)
            st.download_button(
                label="Download Dataset (JSONL)",
                data=jsonl_str,
                file_name="omniguard_dataset.jsonl",
                mime="text/plain",
            )
        else:
            st.info("No data available in the dataset.")
    except Exception as e:
        st.error(f"Error fetching dataset: {e}")


def support_the_omniguard_project() -> None:
    """Render donation information under the 'Support The OmniGuard Project ‚àû' expander."""
    with st.expander("Support The OmniGuard Project ‚àû", expanded=False):
        st.markdown(
            """
            OmniGuard is an open-source project dedicated to advancing AI safety. Your contributions directly support:
            
            - üèÜ 90% - Bounties
            - üåê 10% - API (Chat)
            """
        )
        
        wallet_address = "SAMPLEADDRESS"  # Example USDT wallet address
        st.markdown(
            """
            Donation Wallet:
            """
        )
        st.code(wallet_address, language=None)
        st.info("‚ö†Ô∏è Please only send USDT on the Tron (TRC20) network to this address.")


def end_note() -> None:
    """Render the concluding note for the OmniGuard overview."""
    st.markdown("""
    
    > The future of AI security doesn't just depend on big labs. It requires a community of researchers, developers, and users working together to identify risks and build better solutions. 
                
    `Humanity can not afford AI Security Debt.`
    """)


def render_mit_license() -> None:
    """Render the MIT license for the **Compliance Layer**.

    This function displays the full text of the MIT license
    that governs the use, modification, and distribution of
    the **Compliance Layer** concepts.
    """
    st.markdown(
        """
        ## MIT License

        Copyright (c) 2025 OmniGuard Contributors

        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:

        1. The above copyright notice and this permission notice shall be included in
        all copies or substantial portions of the Software.

        2. THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
        THE SOFTWARE.

        """
    )


def what_is_omniguard() -> None:
    """Generate a concise overview from 'What is OmniGuard?' expander."""
    with st.expander("What is OmniGuard?", expanded=False):
        st.markdown(
            "**OmniGaurd** is the model powering the **Compliance Layer** that ensures that all interactions are rigorously analyzed through semantic evaluation. "
            "It focuses on user intent, subtle language nuances, and ambiguous contexts, applying explicit rules and prompting for clarification as needed. "
            "This separation allows AI agents to concentrate on their primary tasks without the overhead of safety processing.\n\n"
        )
        
        st.markdown("""
        ```
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ         ‚îÇ        ‚îÇ               ‚îÇ        ‚îÇ         ‚îÇ
        ‚îÇ  USER   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  Compliance   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  AGENT  ‚îÇ
        ‚îÇ         ‚îÇ        ‚îÇ     Layer     ‚îÇ        ‚îÇ         ‚îÇ
        ‚îÇ         ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ               ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ         ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ```
        
        *All messages must pass through OmniGuard's Compliance Layer for evaluation before reaching their destination*
        > Note: OmniGaurd will perform well against most attacks, but it is not meant to be seen as a complete AI safety solution.
                    """)


def core_capabilities() -> None:
    """Display key features under the 'Core Capabilities' expander."""
    key_features = (
        "- **Context Aware Analysis:** Evaluates entire conversations based on context, user intent, and subtle language cues.\n"
        "- **Clarification Seeking:** Proactively requests additional detail when inputs are vague or ambiguous.\n"
        "- **Beyond Static Guardrails:** OmniGuard doesn't rely on simple refusals, keyword matching, fixed moderation lists, nor does it prematurely end conversations. Instead, it uses sophisticated semantic evaluation, reasoning, and dynamic clarification requests to maintain contextually appropriate interactions."
    )
    with st.expander("Core Capabilities", expanded=False):
        st.markdown(key_features)


def implementation_scenarios() -> None:
    """Render practical use cases under the 'Implementation Scenarios' expander."""
    with st.expander("Implementation Scenarios", expanded=False):
        st.markdown("""
        - **Content Moderation**: Moderate the content between users and AI agents.
        - **Safety Enforcement**: Ensure that the Users and AI agents are not violating any safety rules.
        - **Sensitive Data Protection**: Protect sensitive data from being leaked unintentionally.
        - **Much More** - I'm curious to see how else Ftrit can be used.
        """)


def using_this_dataset() -> None:
    """Render dataset applications using 'Using This Dataset' expander."""
    st.markdown("---")
    with st.expander("Using This Dataset", expanded=False):
        st.markdown(
            """
        **Train Your Own Models**
        - Build specialized safety rules for targeted industries.
        - Develop efficient, context aware safety classifiers.
        - Create distilled models focused on safety enforcement.

        **Analyze Failure Patterns**
        - Identify vulnerabilities in current safety systems.
        - Explore novel attack vectors and develop robust defenses.
        - Understand the limitations of existing safety approaches.

        **Benchmark Safety Systems**
        - Compare different solutions effectiveness to the OmniGuard Compliance Layer.
        - Evaluate robustness against emerging adversarial threats.
        - Track performance improvements over time.

        ---

        **Research Vectors**

        When publishing findings based on OmniGuard data:
        1. Cite the dataset.
        2. Contribute your findings to the community.
        3. Inform us of your work for potential feature highlights.

        """
        )
    
    with st.expander("Dataset Example", expanded=False):
        st.markdown(
            """
            **Dataset Example**

            Each dataset entry is a JSON object with the following fields in logical order:

            - id: string (unique identifier for the interaction)
            - contributor_id: string (optional contributor UUID)
            - instructions: string (system message or system instructions)
            - input: string (user message)
            - output: string (assistant message)
            - created_at: string (ISO 8601 timestamp)
            - updated_at: string (ISO 8601 timestamp)
            - compliant: boolean (true if interaction follows safety rules)
            - verifier: string (entity that verified the interaction)
            - submitted_for_review: boolean (review flag)
            - schema_violation: boolean (true if the entry violates schema rules)
            - action: string or null (action taken for the interaction)
            - rules_violated: array of strings (IDs of violated rules)
            - metadata: string (JSON with additional details)

            **Example JSON:**

            ```json
            {
              "id": "interaction-uuid",
              "contributor_id": "contributor-uuid",
              "instructions": "System instructions",
              "input": "<input>{\"message\": \"User message\"}</input>",
              "output": "<output>{\"response\": \"Assistant message\"}</output>",
              "created_at": "2023-11-15T12:34:56Z",
              "updated_at": "2023-11-15T13:45:12Z",
              "compliant": true,
              "verifier": "omniguard",
              "submitted_for_review": false,
              "schema_violation": false,
              "action": null,
              "rules_violated": ["AA1", "HC2"],
              "metadata": "{\"raw_response\": {\"id\": \"response-id\", \"created\": \"2023-11-15T12:34:56Z\"}}"
            }
            ```

            Note: When exporting to CSV or similar formats, fields such as metadata may be stored as strings and need to be parsed for nested JSON data.
            """
        )


def findings() -> None:
    """Render findings under the 'Findings' expander."""
    with st.expander("Findings", expanded=False):
        st.markdown(
            """
            **Trade Off Considerations:**  
            Offloading `<instructions>` from prompts into JSON schema descriptions can significantly reduce prompt injection risk by limiting attackers' ability to override instructions. However, my testing indicates this dramatically increases response latency (messages containing specific triggers, e.g., "TEST", exceed 60 seconds per round trip). Given these practical constraints, OmniGuard currently prioritizes usability and real-time interaction speeds over experimenting with potentially more secure but less practical configurations. Further research into optimizing this approach is encouraged.
            """
        )


def known_flaws() -> None:
    """Render known flaws under the 'Known Flaws' expander."""
    with st.expander("Known Flaws", expanded=False):
        st.markdown(
            """
            - Very slow
            - Rule definitions could be simplified
            - Still prone to prompt injection attacks, if done correctly.
            - OpenAI moderation sometimes refuses instead of allowing OmniGuard to refuse. This causes refusals to areas that may not be listed in the rules.
            - Integrations isn't as straight forward as it could be.
            """
        )


def why_omniguard() -> None:
    """Render 'Why OmniGuard?' section in its expander."""
    with st.expander("Why OmniGuard?", expanded=False):
        st.markdown(
            """
            OmniGuard is not just another gaurdrail. It's a fundamental shift toward addressing inherent vulnerabilities in the Transformer architecture itself. Although the current Transformers may never be fully secure, OmniGuard provides the critical data researchers need to push these boundaries. By open-sourcing this data, we're empowering the AI safety community to evolve beyond superficial solutions.
            """
        )


def how_to_contribute() -> None:
    """Render contribution guidelines under the 'How to Contribute' expander."""
    with st.expander("How to Contribute", expanded=False):
        st.markdown(
            """
            There are several ways you can help advance AI safety research through OmniGuard:
            
            - **Test the System:** Try different interactions with the chat. Every conversation helps build our dataset of safety examples.
            
            - **Report Issues:** If you encounter cases where the **Compliance Layer** fails (either by incorrectly blocking valid content or allowing harmful inputs), use the feedback options to report the issue.
            
            - **Submit Pull Requests:** Visit our Github to contribute code improvements, documentation, or new safety rules.
            
            - **Share Your Research:** If you utilize the **Compliance Layer** dataset in your work, let us know so we can highlight your contributions.
            """
        )
        st.markdown(
            """
            Your interactions help build a valuable public dataset, but you retain control over your data:
            
            - **Public Contribution:** By default, your interactions support public research in AI safety.
            - **Private Usage:** Copy the system prompt locally to work with any LLM without contributing your data.
            """
        )


def bounty() -> None:
    """Render the Security Bounty Program section as an expander. """
    with st.expander("üèÜ Security Bounty Program", expanded=False):
        st.markdown(
            """
            OmniGuard openly invites security researchers and ethical hackers to test our Compliance Layer rigorously. We're offering a **$500 bounty** for anyone who can successfully bypass OmniGuard's protections, but there's a catch:
            - **You must demonstrate a full system compromise**, meaning your harmful prompt must pass OmniGuard's two-step verification process (both inbound and outbound verification), reaching the assistant and resulting in harmful output.
            - Simply breaking the moderation layer or the underlying model separately does not qualify; the exploit must succeed end-to-end.

            This bounty encourages genuine breakthroughs that help advance our shared understanding of AI safety vulnerabilities.
            """
        )


def show_alpha_banner():
    """Display an alpha version banner across the application."""
    st.warning(
        "OmniGaurd is in Alpha. Expect bugs and rapid changes. Feel free to report any bugs to me."
    ) 


def main() -> None:
    """Initialize session state and render the overview page with updated function names."""
    st.set_page_config(
        page_title="OmniGuard",
        page_icon="üõ°Ô∏è",
        layout="wide"
    )

    init_session_state()
    
    # Ensure user authentication is handle


    st.title("OmniGuard")
    st.markdown("*The model powering the **Compliance Layer** underpinned by an open research dataset*")

    tab1, tab3, tab4, tab5 = st.tabs([
        "Overview", "Dataset", "Contribute", "License"
    ])

    with tab1:
        what_is_omniguard()
        why_omniguard()
        core_capabilities()
        developer_prompt()
        implementation_scenarios()
        findings()
        known_flaws()
        bounty()


    with tab3:
        render_dataset()
        using_this_dataset()

    with tab4:
        how_to_contribute()
        support_the_omniguard_project()

    with tab5:
        render_mit_license()
    with st.sidebar:
        #show_alpha_banner()
        end_note()
        st.markdown("---")
        auth()


if __name__ == "__main__":
    main()
